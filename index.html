<!-- --> 
<!-- saved from url=(0036)http://appsrv.cse.cuhk.edu.hk/~xchu/ -->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"><HTML 
xml:lang="en" xmlns="http://www.w3.org/1999/xhtml"><HEAD><META 
content="IE=11.0000" http-equiv="X-UA-Compatible">

<META name="GENERATOR" content="MSHTML 11.00.9600.18125">
<META http-equiv="Content-Type" content="text/html;charset=utf-8">
<LINK href="style/jemdoc.css" rel="stylesheet" type="text/css">
<TITLE>Helin Wang</TITLE>
</HEAD>

<BODY>
<div id="particles-js"></div>
<script src="particles.js"></script>
<script src="app.js"></script>
<DIV id="layout-content">
<DIV id="make-narrow">
<DIV id="toptitle">

<H1>Helin Wang</H1></DIV>

<P>
<img src="img/profile.jpg" align="right" style="width:200px;height:210px;"> 
</P>

<P>School of Electronic and Computer Engineering,<BR> Peking University, China</P>
<P><B>Email</B>: wanghl15@pku.edu.cn</P>
<P><B>Phone</B>: +8618813129678</P>
<!-- <P><B>WeChat</B>: wxidbhl</P> -->
<p> 
<a href="https://scholar.google.com/citations?user=I_V0zBMAAAAJ&hl=zh-CN"><img src="./img/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
<a href="https://dblp.org/pid/180/6754.html"><img src="./img/dblp.png" height="30px" style="margin-bottom:-3px"></a>
<a href="https://github.com/WangHelin1997"><img src="./img/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
<a href="https://www.linkedin.com/in/%E8%B5%AB%E9%BA%9F-%E7%8E%8B-2a74671b3/"><img src="./img/LinkedIn_s.png" height="30px" style="margin-bottom:-3px"></a>
</p>
<P><A href="assets/cv.pdf">[Curriculum Vitae]</A></P>
<!-- <P><A href="https://dblp.uni-trier.de/pers/hd/b/Bai:Haoli">[DBLP]</A> -->
<!-- <A href="https://github.com/haolibai">[GitHub]</A> -->
<!--<a href="http://appsrv.cse.cuhk.edu.hk/~hlbai/CV_Haoli.pdf">[CV]</A>-->
</P>


<H2>General</H2>
    <P>I am a second-year master student at Peking University, majoring in Speech and Audio Processing.<BR> Before that, I received the Bachelor's Degree from Tsinghua University in 2019. <BR>(<B>Note:</B> I will graduate in July 2022, and I am actively looking for <B>PhD opportunities</B> starting from <B>2022 Fall</B>. Please feel free to contact me.)

<H2>Research Interests</H2>
<P>Machine Learning, Audio Processing, Speech Processing</P>

<H2>Educations</H2>
  <div style="overflow:hidden;margin-bottom: 0.6em">
    <div style="float:left;"></div>
  </div>

<UL>
  <LI>
    <div style="float:left;">School of Electronic and Computer Engineering, <A href="http://www.pku.edu.cn/"> Peking University</A></div>
    <div style="float:right;">August 2019 - Now.</div>
  </LI>
</UL>

<UL>
  <LI>
    <div style="float:left;">Department of Automation, <A href="http://www.tsinghua.edu.cn/"> Tsinghua University</A></div>
    <div style="float:right;">August 2015 - July 2019.</div>
  </LI>
</UL>

<H2>Experiences</H2>
<UL>
  <LI>
  <P>May 2021 - Now<BR>
      <B>National University of Singapore</B>, Human Language Technology, Summer Research. <BR>(Supervised by <A href="https://scholar.google.com.sg/citations?user=z8_x7C8AAAAJ"> Haizhou Li </A>)
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P>May 2020 - Now<BR>
      <B>Tencent AI Lab</B>, Speech Group, Intern. <BR>(Supervised by <A href="https://scholar.google.com/citations?user=s62BKJIAAAAJ&hl=zh-CN"> Bo Wu </A> and <A href="https://scholar.google.com/citations?hl=zh-CN&user=pRA19-8AAAAJ"> Chao Weng</A>)
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P>August 2019 - Now<BR>
      <B>Peking University</B>, ADSP Lab, master student. <BR>(Supervised by <A href="https://scholar.google.com/citations?user=sfyr7zMAAAAJ"> Yuexian Zou</A>)
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P>July 2019 - September 2019<BR>
      <B>Ubtech Robotics Inc.</B>, Speech Group, Intern. <BR>(Supervised by <A href="https://dblp.org/pid/119/9254.html"> Dongyan Huang</A>)
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P>July 2018 - September 2018<BR>
      <B>University of California Berkeley</B>, California Path Lab, Summer Research. <BR>(Supervised by <A href="https://me.berkeley.edu/people/masayoshi-tomizuka/"> Masayoshi Tomizuka</A>)
   </P>
  </LI>
</UL>

<H2>Publications</H2>
<!-- <p>(Conference: 3 & Journal: 0)</p> -->
<UL>
  <LI>
  <P><B>Helin Wang</B>, Yuexian Zou, Wenwu Wang <BR>
    <A href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9414357"> A Global-local Attention Framework for Weakly Labelled Audio Tagging </A><BR>
    <I>ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</I>, 2021.
    <A href="https://github.com/WangHelin1997/GL-AT">[Code]</A>
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P>Haoran Zhang, Yuexian Zou, <B>Helin Wang</B> <BR>
    <A href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9413351">Contrastive Self-supervised Learning for Text-independent Speaker Verification </A><BR>
    <I>ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</I>, 2021.
   </P>
  </LI>
</UL> 

<UL>
  <LI>
  <P>Zhiqi Huang, Fenglin Liu, Xian Wu, Shen Ge, <B>Helin Wang</B>, Wei Fan, Yuexian Zou. <BR>
    <A href="http://web.pkusz.edu.cn/adsp/files/2021/01/AAAI.HuangZ.pdf">Audio-Oriented Multimodal Machine Comprehension via Dynamic Inter- and Intra-modality Attention </A><BR>
    <I>Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI)</I>, 2021.
    <A href="https://github.com/mazicwong/AOM-MC">[Code]</A>
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P><B>Helin Wang</B>, Yuexian Zou, Dading Chong, Wenwu Wang <BR>
    <A href="https://arxiv.org/pdf/1912.06808.pdf"> Environmental Sound Classification with Parallel Temporal-spectral Attention </A><BR>
    <I>Proc. Interspeech</I>, 2020.
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P><B>Helin Wang</B>, Yuexian Zou, Dading Chong, Wenwu Wang <BR>
    <A href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9178483"> Modeling Label Dependencies for Audio Tagging with Graph Convolutional Network </A><BR>
    <I>IEEE Signal Processing Letters</I>, 2020.
      <A href="https://github.com/WangHelin1997/AT-GCN">[Code]</A>
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P><B>Helin Wang</B>, Yuexian Zou, Dading Chong <BR>
    <A href="https://arxiv.org/pdf/2007.03781.pdf"> Acoustic Scene Classification With Spectrogram Processing Strategies </A><BR>
    <I>Workshop on Detection and Classification of Acoustic Scenes and Events (DCASE)</I>, 2020.
      <A href="https://github.com/WangHelin1997/DCASE-2020-Task1A-Code">[Code]</A>
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P><B>Helin Wang</B>, Bang Yang, Yuexian Zou, Dading Chong <BR>
    <A href="https://dcase.community/documents/challenge2020/technical_reports/DCASE2020_Wang_5_t6.pdf"> Automated Audio Captioning with Temporal Attention </A><BR>
    <I>Challenge on Detection and Classification of Acoustic Scenes and Events (DCASE)</I>, 2020.
      <A href="https://github.com/WangHelin1997/DCASE2020-Task6-PKU">[Code]</A>
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P><B>Helin Wang</B>, Dading Chong, Yuexian Zou, Dongyan Huang <BR>
    <A href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8925277"> What Affects the Performance of Convolutional Neural Networks for Audio Event Classification </A><BR>
    <I>2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)</I>, 2019.
      <A href="https://github.com/WangHelin1997/FPNet">[Code]</A>
   </P>
  </LI>
</UL>

<H2>Preprints</H2>
<!-- <p>(Conference: 3 & Journal: 0)</p> -->
<UL>
  <LI>
  <P><B>Helin Wang</B>, Yuexian Zou, Wenwu Wang <BR>
      SpecAugment++: A Hidden Space Data Augmentation Method for Acoustic Scene Classification <BR>
      Submitted to Interspeech 2021.
   </P>
  </LI>
</UL>
<UL>
  <LI>
  <P><B>Helin Wang</B>, Bo Wu, Lianwu Chen, Meng Yu, Jianwei Yu, Yong Xu, Shi-Xiong Zhang, Chao Weng, Dan Su, Dong Yu <BR>
      TeCANet: Temporal-Contextual Attention Network for Environment-aware Speech Dereverberation <BR>
      Submitted to Interspeech 2021.
   </P>
  </LI>
</UL>
<UL>
  <LI>
  <P>Dongchao Yang, <B>Helin Wang</B>, Yuexian Zou <BR>
      Unsupervised Multi-Target Domain Adaptation for Acoustic Scene Classification <BR>
      Submitted to Interspeech 2021.
   </P>
  </LI>
</UL>
<UL>
  <LI>
  <P>Jinchuan Tian, Rongzhi Gu, <B>Helin Wang</B>, Yuexian Zou <BR>
      Layer Reduction: Accelerating Conformer-Based Self-Supervised Model via Layer Consistency <BR>
      Submitted to Interspeech 2021.
   </P>
  </LI>
</UL>
<UL>
  <LI>
  <P>Li Wang, Rongzhi Gu, <B>Helin Wang</B>, Yuexian Zou<BR>
      Decoupling Feature Learning for Keyword Spotting and Speaker Verification via Orthogonal Convolution <BR>
      Submitted to Interspeech 2021.
   </P>
  </LI>
</UL>


<H2>Projects</H2>
<UL>
  <LI>
      <P><B>Major Member</B>: Research on Deep Analysis Method of Acoustic Scenes for Smart Home Robot <BR>
    The project is a Shenzhen Science and Technology Fundamental Research Program, which studies the acoustic scenes and events in real home environments, including robust acoustic feature extraction, acoustic scene classification methods, abnormal sound event detection and warning.<BR>
   </P>
  </LI>
</UL>

<UL>
  <LI>
      <P><B>Leader</B>: Research on Multi-modal Health Monitoring System based on Infant Voices <BR>
    The project is a Shenzhen Science and Technology Fundamental Research Program, which studies the physiological characteristics of infant and conducts abnormal event detection based on audio and video signals. <BR>
   </P>
  </LI>
</UL>

<H2>Services</H2>
  <div style="overflow:hidden;margin-bottom: 0.6em">
    <div style="float:left;"></div>
  </div>

<UL>
  <LI>
    <div style="float:left;">TASLP, Neurocomputing, Interspeech, ICASSP</div>
    <div style="float:right;">Reviewer (or PC Member)</div>
  </LI>
</UL>

<H2>Selected Awards</H2>
    <div style="overflow:hidden;margin-bottom: 0.6em">
     <div style="float:left;">6th Team Ranking of DCASE Challenge Task 1</div>
     <div style="float:right;">2020</div>
    </div>
   
    <div style="overflow:hidden;margin-bottom: 0.6em">
     <div style="float:left;">3rd Team Ranking of DCASE Challenge Task 6</div>
     <div style="float:right;">2020</div>
    </div>

    <div style="overflow:hidden;margin-bottom: 0.6em">
     <div style="float:left;">3rd Prize of Peking University</div>
     <div style="float:right;">2019-2020</div>
    </div>


<div id="footer">
  <div id="footer-text"></div>
</div>
<a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fwanghelin1997.github.io%2Fhelinwang%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a>
<p><center>
<div id="clustrmaps-widget" style="width:50%">
<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=QzXBa4ziRwuAQXpOVUeAtaD3JogYtR4qK4GIEVjmHNI&cl=ffffff&w=a"></script>
</div>
</center></p>
</div>

</DIV></DIV>
</BODY></HTML>
