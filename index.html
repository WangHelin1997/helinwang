<!-- --> 
<!-- saved from url=(0036)http://appsrv.cse.cuhk.edu.hk/~xchu/ -->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"><HTML 
xml:lang="en" xmlns="http://www.w3.org/1999/xhtml"><HEAD><META 
content="IE=11.0000" http-equiv="X-UA-Compatible">

<META name="GENERATOR" content="MSHTML 11.00.9600.18125">
<META http-equiv="Content-Type" content="text/html;charset=utf-8">
<LINK href="style/jemdoc.css" rel="stylesheet" type="text/css">
<TITLE>Helin Wang</TITLE>
</HEAD>

<BODY>
<!--<div id="particles-js" class="particles-js"></div>-->
<!--<script src="./particles.js"></script>-->
<!--<script src="./app.js"></script>-->
<DIV id="layout-content">
<DIV id="make-narrow">
<DIV id="toptitle">

<H1>Helin Wang</H1></DIV>

<P>
<img src="img/profile.jpg" align="right" style="width:200px;height:210px;"> 
</P>

<P>School of Electronic and Computer Engineering,<BR> Peking University, China</P>
<P><B>Email</B>: wanghl15@pku.edu.cn</P>
<P><B>Phone</B>: +8618813129678</P>
<!-- <P><B>WeChat</B>: wxidbhl</P> -->
<p> 
<a href="https://scholar.google.com/citations?user=I_V0zBMAAAAJ"><img src="./img/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
<a href="https://dblp.org/pid/180/6754.html"><img src="./img/dblp.png" height="30px" style="margin-bottom:-3px"></a>
<a href="https://github.com/WangHelin1997"><img src="./img/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
<a href="https://www.linkedin.com/in/helin-wang-2a74671b3/"><img src="./img/LinkedIn_s.png" height="30px" style="margin-bottom:-3px"></a>
</p>
<P><A href="assets/cv.pdf">[Curriculum Vitae]</A></P>
<!-- <P><A href="https://dblp.uni-trier.de/pers/hd/b/Bai:Haoli">[DBLP]</A> -->
<!-- <A href="https://github.com/haolibai">[GitHub]</A> -->
<!--<a href="http://appsrv.cse.cuhk.edu.hk/~hlbai/CV_Haoli.pdf">[CV]</A>-->
</P>


<H2>General</H2>
<!--    <P>I am a third-year PhD student at Peking University, majoring in Speech and Audio Processing.<BR> Before that, I received the Bachelor's Degree from Tsinghua University in 2019. <BR>-->
    <P>I am a final year master student at Peking University, majoring in Speech and Audio Processing.<BR> Before that, I received the Bachelor's Degree from Tsinghua University in 2019. <BR>(<B>Note:</B> I will graduate in July 2022, and I am actively looking for <B>PhD opportunities</B> and <B>industrial opportunities</B> starting from <B>2022 Fall</B>. Please feel free to contact me.)

<H2>Research Interests</H2>
<P>Machine Learning, Audio Processing, Speech Processing</P>

<H2>Educations</H2>
  <div style="overflow:hidden;margin-bottom: 0.6em">
    <div style="float:left;"></div>
  </div>

<UL>
  <LI>
    <div style="float:left;">School of Electronic and Computer Engineering, <A href="http://www.pku.edu.cn/"> Peking University</A></div>
    <div style="float:right;">August 2019 - Now.</div>
  </LI>
</UL>

<UL>
  <LI>
    <div style="float:left;">Department of Automation, <A href="http://www.tsinghua.edu.cn/"> Tsinghua University</A></div>
    <div style="float:right;">August 2015 - July 2019.</div>
  </LI>
</UL>

<H2>Experiences</H2>
<!--<UL>-->
<!--  <LI>-->
<!--  <P>May 2021 - Now<BR>-->
<!--      <B>National University of Singapore</B>, Human Language Technology, Summer Research. <BR>(Supervised by <A href="https://scholar.google.com.sg/citations?user=z8_x7C8AAAAJ"> Haizhou Li</A>)-->
<!--   </P>-->
<!--  </LI>-->
<!--</UL>-->

<UL>
  <LI>
  <P>May 2020 - November 2021<BR>
      <B>Tencent AI Lab</B>, <A href="https://ai.tencent.com/ailab/en/index"> Speech Group</A>, Intern. <BR> Supervisor: <A href="https://scholar.google.com/citations?user=s62BKJIAAAAJ"> Bo Wu </A>, <A href="https://scholar.google.com/citations?user=OSM9xooAAAAJ"> Yi Luo </A> and <A href="https://scholar.google.com/citations?user=pRA19-8AAAAJ"> Chao Weng</A>
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P>August 2019 - Now<BR>
      <B>Peking University</B>, <A href="https://web.pkusz.edu.cn/adsp/"> ADSP Lab</A>, master student. <BR> Supervisor: <A href="https://scholar.google.com/citations?user=sfyr7zMAAAAJ"> Yuexian Zou</A> <BR> Co-author: <A href="https://scholar.google.co.uk/citations?user=JQFnV5IAAAAJ"> Wenwu Wang</A>
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P>July 2019 - September 2019<BR>
      <B>Ubtech Robotics Inc.</B>, Speech Group, Intern. <BR> Supervisor: <A href="https://dblp.org/pid/119/9254.html"> Dongyan Huang</A>
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P>July 2018 - September 2018<BR>
      <B>University of California Berkeley</B>, <A href="https://path.berkeley.edu/"> California Path Lab</A>, Summer Research. <BR> Supervisor: <A href="https://me.berkeley.edu/people/masayoshi-tomizuka/"> Masayoshi Tomizuka</A>
   </P>
  </LI>
</UL>

<H2>Publications</H2>
<!-- <p>(Conference: 3 & Journal: 0)</p> -->
<UL>
  <LI>
  <P><B>Helin Wang</B>, Yuexian Zou, Wenwu Wang <BR>
    <A href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/wang21d_interspeech.pdf"> SpecAugment++: A Hidden Space Data Augmentation Method for Acoustic Scene Classification </A><BR>
    <I>Proc. Interspeech</I>, 2021.
    <A href="https://github.com/WangHelin1997/SpecAugment-plus">[Code]</A>
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P><B>Helin Wang</B>, Bo Wu, Lianwu Chen, Meng Yu, Jianwei Yu, Yong Xu, Shi-Xiong Zhang, Chao Weng, Dan Su, Dong Yu <BR>
    <A href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/wang21l_interspeech.pdf"> TeCANet: Temporal-Contextual Attention Network for Environment-aware Speech Dereverberation </A><BR>
    <I>Proc. Interspeech</I>, 2021.
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P><B>Helin Wang</B>, Yuexian Zou, Wenwu Wang <BR>
    <A href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9414357"> A Global-local Attention Framework for Weakly Labelled Audio Tagging </A><BR>
    <I>ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</I>, 2021.
    <A href="https://github.com/WangHelin1997/GL-AT">[Code]</A>
   </P>
  </LI>
</UL>


<UL>
  <LI>
  <P><B>Helin Wang</B>, Yuexian Zou, Dading Chong, Wenwu Wang <BR>
    <A href="http://www.interspeech2020.org/uploadfile/pdf/Mon-2-8-2.pdf"> Environmental Sound Classification with Parallel Temporal-spectral Attention </A><BR>
    <I>Proc. Interspeech</I>, 2020.
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P><B>Helin Wang</B>, Yuexian Zou, Dading Chong, Wenwu Wang <BR>
    <A href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9178483"> Modeling Label Dependencies for Audio Tagging with Graph Convolutional Network </A><BR>
    <I>IEEE Signal Processing Letters</I>, 2020.
      <A href="https://github.com/WangHelin1997/AT-GCN">[Code]</A>
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P><B>Helin Wang</B>, Yuexian Zou, Dading Chong <BR>
    <A href="http://dcase.community/documents/workshop2020/proceedings/DCASE2020Workshop_Wang_58.pdf"> Acoustic Scene Classification With Spectrogram Processing Strategies </A><BR>
    <I>Workshop on Detection and Classification of Acoustic Scenes and Events (DCASE)</I>, 2020.
      <A href="https://github.com/WangHelin1997/DCASE-2020-Task1A-Code">[Code]</A>
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P><B>Helin Wang</B>, Bang Yang, Yuexian Zou, Dading Chong <BR>
    <A href="https://dcase.community/documents/challenge2020/technical_reports/DCASE2020_Wang_5_t6.pdf"> Automated Audio Captioning with Temporal Attention </A><BR>
    <I>Challenge on Detection and Classification of Acoustic Scenes and Events (DCASE)</I>, 2020.
      <A href="https://github.com/WangHelin1997/DCASE2020-Task6-PKU">[Code]</A>
   </P>
  </LI>
</UL>

<UL>
  <LI>
  <P><B>Helin Wang</B>, Dading Chong, Yuexian Zou, Dongyan Huang <BR>
    <A href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8925277"> What Affects the Performance of Convolutional Neural Networks for Audio Event Classification </A><BR>
    <I>2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)</I>, 2019.
      <A href="https://github.com/WangHelin1997/FPNet">[Code]</A>
   </P>
  </LI>
</UL>
<UL>
  <LI>
  <P>Dongchao Yang, <B>Helin Wang</B>, Yuexian Zou <BR>
    <A href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/yang21b_interspeech.pdf"> Unsupervised Multi-Target Domain Adaptation for Acoustic Scene Classification </A><BR>
    <I>Proc. Interspeech</I>, 2021.
    <A href="https://github.com/yangdongchao/interspeech2021_MTDA">[Code]</A>
   </P>
  </LI>
</UL>
<UL>
  <LI>
  <P>Haoran Zhang, Yuexian Zou, <B>Helin Wang</B> <BR>
    <A href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9413351">Contrastive Self-supervised Learning for Text-independent Speaker Verification </A><BR>
    <I>ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</I>, 2021.
   </P>
  </LI>
</UL>
<UL>
  <LI>
  <P>Zhiqi Huang, Fenglin Liu, Xian Wu, Shen Ge, <B>Helin Wang</B>, Wei Fan, Yuexian Zou. <BR>
    <A href="http://web.pkusz.edu.cn/adsp/files/2021/01/AAAI.HuangZ.pdf">Audio-Oriented Multimodal Machine Comprehension via Dynamic Inter- and Intra-modality Attention </A><BR>
    <I>Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI)</I>, 2021.
    <A href="https://github.com/mazicwong/AOM-MC">[Code]</A>
   </P>
  </LI>
</UL>
<UL>
  <LI>
  <P>Dongchao Yang, <B>Helin Wang</B>, Zhongjie Ye, Yuexian Zou <BR>
    <A href="http://dcase.community/documents/challenge2021/technical_reports/DCASE2021_Zou_22_task5.pdf"> Few-shot Bioacoustic Event Detection: A Good Transductive Inference is All You Need </A><BR>
    <I>Challenge on Detection and Classification of Acoustic Scenes and Events (DCASE)</I>, 2021.
      <A href="https://github.com/yangdongchao/DCASE2021Task5">[Code]</A>
   </P>
  </LI>
</UL>
<UL>
  <LI>
  <P>Zhongjie Ye, <B>Helin Wang</B>, Dongchao Yang, Yuexian Zou <BR>
    <A href="http://dcase.community/documents/challenge2021/technical_reports/DCASE2021_Zou_22_task5.pdf"> Improving the Performance of Automated Audio Captioning via Integrating the Acoustic and Textual Information </A><BR>
    <I>Challenge on Detection and Classification of Acoustic Scenes and Events (DCASE)</I>, 2021.
      <A href="https://github.com/WangHelin1997/DCASE2021_Task6_PKU">[Code]</A>
   </P>
  </LI>
</UL>
<!--<H2>Preprints</H2>-->
<!--&lt;!&ndash; <p>(Conference: 3 & Journal: 0)</p> &ndash;&gt;-->
<!--<UL>-->
<!--  <LI>-->
<!--  <P><B>Helin Wang</B>, Yuexian Zou, Wenwu Wang <BR>-->
<!--      SpecAugment++: A Hidden Space Data Augmentation Method for Acoustic Scene Classification <BR>-->
<!--      Submitted to Interspeech 2021.-->
<!--   </P>-->
<!--  </LI>-->
<!--</UL>-->
<!--<UL>-->
<!--  <LI>-->
<!--  <P><B>Helin Wang</B>, Bo Wu, Lianwu Chen, Meng Yu, Jianwei Yu, Yong Xu, Shi-Xiong Zhang, Chao Weng, Dan Su, Dong Yu <BR>-->
<!--      TeCANet: Temporal-Contextual Attention Network for Environment-aware Speech Dereverberation <BR>-->
<!--      Submitted to Interspeech 2021.-->
<!--   </P>-->
<!--  </LI>-->
<!--</UL>-->
<!--<UL>-->
<!--  <LI>-->
<!--  <P>Dongchao Yang, <B>Helin Wang</B>, Yuexian Zou <BR>-->
<!--      Unsupervised Multi-Target Domain Adaptation for Acoustic Scene Classification <BR>-->
<!--      Submitted to Interspeech 2021.-->
<!--   </P>-->
<!--  </LI>-->
<!--</UL>-->
<!--<UL>-->
<!--  <LI>-->
<!--  <P>Jinchuan Tian, Rongzhi Gu, <B>Helin Wang</B>, Yuexian Zou <BR>-->
<!--      Layer Reduction: Accelerating Conformer-Based Self-Supervised Model via Layer Consistency <BR>-->
<!--      Submitted to Interspeech 2021.-->
<!--   </P>-->
<!--  </LI>-->
<!--</UL>-->
<!--<UL>-->
<!--  <LI>-->
<!--  <P>Li Wang, Rongzhi Gu, <B>Helin Wang</B>, Yuexian Zou<BR>-->
<!--      Decoupling Feature Learning for Keyword Spotting and Speaker Verification via Orthogonal Convolution <BR>-->
<!--      Submitted to Interspeech 2021.-->
<!--   </P>-->
<!--  </LI>-->
<!--</UL>-->


<H2>Projects</H2>
<UL>
  <LI>
      <P><B>Leader</B>: Research on Deep Analysis Method of Acoustic Scenes for Smart Home Robot <BR>
    The project is a Shenzhen Science and Technology Fundamental Research Program, which studies the acoustic scenes and events in real home environments, including robust acoustic feature extraction, acoustic scene classification methods, abnormal sound event detection and warning.<BR>
   </P>
  </LI>
</UL>

<UL>
  <LI>
      <P><B>Leader</B>: Research on Multi-modal Health Monitoring System based on Infant Voices <BR>
    The project is a Shenzhen Science and Technology Fundamental Research Program, which studies the physiological characteristics of infant and conducts abnormal event detection based on audio and video signals. <BR>
   </P>
  </LI>
</UL>

<H2>Services</H2>
  <div style="overflow:hidden;margin-bottom: 0.6em">
    <div style="float:left;"></div>
  </div>

<UL>
  <LI>
    <div style="float:left;">TASLP, Neurocomputing, Interspeech, ICASSP</div>
    <div style="float:right;">Reviewer (or PC Member)</div>
  </LI>
</UL>

<H2>Selected Awards</H2>
    <div style="overflow:hidden;margin-bottom: 0.6em">
     <div style="float:left;">1st Team Ranking of <A href="http://dcase.community/challenge2021/task-few-shot-bioacoustic-event-detection"> DCASE Challenge Task 5</A> <A href="http://dcase.community/challenge2019/awards"> (Judges’ award)</A> </div>
     <div style="float:right;">2021</div>
    </div>

    <div style="overflow:hidden;margin-bottom: 0.6em">
     <div style="float:left;">4th Team Ranking of <A href="http://dcase.community/challenge2021/task-automatic-audio-captioning"> DCASE Challenge Task 6</A> <A href="http://dcase.community/challenge2019/awards"> (Judges’ award)</A> </div>
     <div style="float:right;">2021</div>
    </div>

    <div style="overflow:hidden;margin-bottom: 0.6em">
     <div style="float:left;">6th Team Ranking of <A href="http://dcase.community/challenge2020/task-acoustic-scene-classification"> DCASE Challenge Task 1</A></div>
     <div style="float:right;">2020</div>
    </div>
   
    <div style="overflow:hidden;margin-bottom: 0.6em">
     <div style="float:left;">3rd Team Ranking of <A href="http://dcase.community/challenge2020/task-automatic-audio-captioning"> DCASE Challenge Task 6</A></div>
     <div style="float:right;">2020</div>
    </div>

    <div style="overflow:hidden;margin-bottom: 0.6em">
     <div style="float:left;">Award for Scientific Research of Peking University</div>
     <div style="float:right;">2020-2021</div>
    </div>

    <div style="overflow:hidden;margin-bottom: 0.6em">
     <div style="float:left;">School Prize of Peking University</div>
     <div style="float:right;">2019-2020</div>
    </div>

    <div style="overflow:hidden;margin-bottom: 0.6em">
     <div style="float:left;">Merit Student of Peking University</div>
     <div style="float:right;">2019-2020</div>
    </div>


<div id="footer">
  <div id="footer-text"></div>
</div>
<a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fwanghelin1997.github.io%2Fhelinwang%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a>
<p><center>
<div id="clustrmaps-widget" style="width:50%">
<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=QzXBa4ziRwuAQXpOVUeAtaD3JogYtR4qK4GIEVjmHNI&cl=ffffff&w=a"></script>
</div>
</center></p>
</div>

</DIV></DIV>
</BODY></HTML>
